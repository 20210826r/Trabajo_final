Institución,Título de la tesis,Nombre del tesista,Grado,Nombre del asesor,Resumen,Año
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Estimación del ciclo financiero utilizando métodos de análisis exploratorios: aplicación a Perú en el periodo 2000-2021,"Atoche Murrieta, Lilian Katherine",Magíster en Estadística,"Camiz, Sergio","The objective of this thesis is to identify the financial cycle of Peru using financial time series such as active and passive interest rates, total savings amount in the financial system, liquidity of financial entities, among others. The information is monthly and covers the periods 2000-2021. Exploratory analysis techniques are used to determine the financial cycle. We first started with the principal components analysis which allowed us to identify if there are common components among the variables. We then use a hierarchical classification (HFC) to group the variables into homogeneous groups. This analysis allowed us to associate each group with a representative variable which allowed us to identify the components of the fi- nancial cycle. Finally, we use a third exploratory technique known as evolutionary analysis, which aims to identify whether the correlation of the series varies over time. The results of the exploratory analysis confirm the existence of three components of the financial cycle. The first component identifies the long-term component of the financial cycle. This component measures the evolution of the financial system over time. The second component measures the evolution of lending and deposit rates in the financial system, which is a medium-term component. The third component can be associated with the volatility of the Peruvian fi- nancial market.",2022-09-22
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Método para la fusión de categorías usando técnicas de agrupamiento,"Farro Diaz, Victor Daniel",Magíster en Estadística,"Bayes Rodriguez, Cristian Luis","En la actualidad, muchas organizaciones disponen o tienen acceso a una gran cantidad y variedad de datos que les permiten tomar decisiones acordes en temas económicos, sociales, de educación, de salud, entre otros. Con frecuencia, los estudios que se realizan se enfocan en el objetivo de explicar una variable de interés utilizando un conjunto de variables explicativas; y si la relación de dependencia es lineal, se le conoce como modelo de regresión lineal. Los modelos de regresión lineal presentan su principal reto en la estimación de los parámetros de la regresión, que se consiguen a partir de la información obtenida mediante el análisis de las observaciones de una muestra previamente recogida. La complejidad de los modelos de regresión lineal aumenta con la existencia de covariables que son medidas en una escala nominal u ordinal, y que en muchas ocasiones presentan una gran cantidad de categorías, como por ejemplo: estado civil, grupo sanguíneo, entre otros. Lo habitual para modelar el efecto total de una covariable categórica es definir una categoría (o nivel) como línea base y utilizar variables ficticias para las otras categorías (o niveles).
La presente tesis tiene como principal objetivo el desarrollo del método de fusión de efectos de covariables categóricas usando técnicas de agrupamiento PAM, propuesto por Malsiner-Walli, Pauger y Wagner (2018), y aplicarlo en un conjunto de datos reales relacionados a los ingresos monetarios de la población de Lima Metropolitana y Callao del primer trimestre del 2020.",2022-04-28
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Redes neuronales convolucionales para datos composicionales: Una aplicación a la industria textil de la moda,"Cotacallapa Amanqui, Pavel Arturo",Magíster en Estadística,"Benites Sanchez, Luis Enrique","En muchas situaciones prácticas es necesario el uso de modelos que puedan predecir una colección
de datos limitados por un intervalo cuya suma sea una constante por cada unidad estadística.
Este tipo de variable respuesta se conoce como datos composicionales. Por otro lado, el número de
covariables que se usan para el entrenamiento de este tipo de modelos pueden provenir de datos
asociados a imágenes como la intensidad de los pixeles. En ese contexto, se propone el uso de las
redes neuronales convolucionales como una primera alternativa para intentar estimar este tipo de
variable respuesta. Se utiliza la distribución de Dirichlet como distribución condicional de los datos
y  nalmente se propone una aplicación del modelo utilizando imágenes de prendas de vestir que se
venden por catálogo en donde el objetivo es predecir las participaciones de las tallas que se venden
por cada unidad estadística.",2022-04-07
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Modelo de regresión cuantílica para respuestas positivas con censura intervalar,"Manrique Urbina, Justo Andrés",Magíster en Estadística,"Bayes Rodriguez, Cristian Luis","La presente tesis propone un modelo de regresi on cuant  lica en d onde la variable es no
negativa y posee censura intervalar, es decir que esta no es directamente observable, y la  unica
informaci on que se conoce sobre ella es que se encuentra en cierto intervalo. Para evaluar si
la metodolog  a de estimaci on captura adecuadamente los par ametros poblacionales desde el
punto de vista de la inferencia cl asica, se desarrolla un estudio de simulaci on. Finalmente, se
aplica el modelo a los datos de la Encuesta Nacional de Satisfacci on de Salud ejecutada el
a~no 2015. La estructura del modelo permite evaluar los factores relacionados al sueldo de los
profesionales en salud (el cual hab  a sido censurado desde el proceso de recolecci on de datos).
El presente modelo es una extensi on al modelo de regresi on de censura intervalar expuesto
en Sal y Rosas et al. (2019), pues eval ua los factores subyacentes a una variable respuesta a
lo largo de sus cuantiles.",2022-03-21
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Clasiﬁcación de riesgo para frecuencias y severidades en un seguro de automóviles usando modelos GAMLSS,"Hernández Bello, Diana Patricia",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","En la tariﬁcación de seguros generales, en particular en seguros de vehículos, es valioso incorporar toda la información disponible del asegurado, del bien asegurado y de los siniestros que se han presentado, con el ﬁn de obtener modelos que consideren las variables relevantes en la estimación y así generar una prima de riesgo adecuada para el riesgo que se está analizando.
Los modelos a considerar están construidos con base en las reclamaciones que ha presentado el asegurado y su estimaci´on se obtiene mediante distribuciones del número y monto de siniestros dando como resultado tarifas que incluyen recargos y descuentos en base a la experiencia siniestral, lo que se conoce como Sistema Bonus-Malus. Adicionalmente se han analizado modelos de regresión que incluyen información tanto del asegurado como del vehículo y cuya estimación de la prima de riesgo se realiza a través de la media tanto de la frecuencia como de la severidad. Sin embargo, dado que los riesgos en la cartera expuesta son heterogéneos, se plantean también modelos de regresión en los que la estimación de la frecuencia y la severidad se realiza a través de parámetros como: la media, la varianza, el sesgo y la curtosis, estos últimos son denominados modelos aditivos generalizados de localización, escala y forma (GAMLSS).",2022-03-16
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Approximate bayesian inference for directed acyclic graph autoregressive models,"Buendía Narváez, Julio César",Magíster en Estadística,"Quiroz Cornejo, Zaida Jesús","The prevalence of epidemiological diseases collected in geographically limited areas, such
as districts or provinces, are crucial for making public health decisions. It is common that
this response variable presents spatial dependence, that is, it is similar in neighboring areas,
due to the nature of the disease, weather, economy and cultural level, among other reasons.
In this sense, spatial models for areal data are proposed to identify trends and factors associated
with epidemiological diseases, taking into account the spatial dependence between
geographic areas. Usually, these models  t the spatial dependence through spatial random
e ects built from graphs and conditional distributions. In particular, the directed acyclic
graph autoregressive (DAGAR) model is based on a directed acyclic graph and some \past""
random e ects. As a consequence, the precision matrix (inverse of the covariance) of the
model is sparse. This model has an intuitive interpretation of the parameters associated
with spatial dependence and can be represented as a latent Gaussian model. In this context,
we propose in this project to implement the DAGAR model throughout the approximate
Bayesian inference method INLA which is deterministic, quite accurate and e cient. Within
this approach, estimation of large data can be carried out in seconds or minutes, and it allows
to  t data following a Gaussian distribution or non-Gaussian distributions. Finally, in order
to show the contribution of this proposal, the DAGAR model will be  tted to real data.",2022-02-02
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Fusión de efectos para modelos de regresión con respuesta positiva bajo un enfoque bayesiano,"Dongo Román, Andie Bryan",Magíster en Estadística,"Bayes Rodriguez, Cristian Luis","El presente trabajo tiene como objetivo adaptar el modelo bayesiano para fusión de efectos presentado por Pauger y Wagner (2019), de tal manera que sea adecuado para modelos de regresión con respuesta positiva bajo una distribución gamma. El modelo plantea como distribución a priori de los coeficientes de cada covariable cualitativa a una normal multivariada, deducida a partir de una distribución a priori spike y slab para la diferencia de cada par de efectos, cuya matriz de precisión permite conocer qué niveles pueden fusionarse.
La estructura de la matriz de precisión depende de un hiperparámetro que permite estimar las probabilidades de fusión a posteriori entre cada par de niveles, con las cuales se pueden agrupar aquellos niveles con efectos similares mediante la función de pérdida de Binder. La estimación a posteriori del modelo es realizada con métodos MCMC utilizando el programa JAGS en R.
Se aplicó la metodología a un conjunto de datos reales extraído de la Encuesta Nacional de Hogares (ENAHO) del año 2019, donde se pudo verificar la existencia de una brecha salarial por etnicidad en los entrevistados de la macro región sur del Perú. Así mismo, se incluyó en el caso aplicativo a la interacción entre los efectos de la etnicidad y el sexo, revelándose que la brecha por género existente es mayor en la población aymara y en la no indígena, en comparación con la población quechua.",2022-01-10
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Identificación de conglomerados espaciales de acuerdo a niveles de morosidad de empresas en el Perú,"Tristán Gómez, Alex Edward",Magíster en Estadística,"Quiroz Cornejo, Zaida Jesús","Compliance with the  nancial obligations of companies is ensured by proper credit risk
management, this avoids liquidity and solvency problems. For this reason, it is important to
identify the risk level of default in peruvian companies. The goal of this thesis is to identify
clusters of provinces of Per u with regard to the default rate of payments, also known as
probability of default. Thus it is proposed a model in two stages. In the  rst stage hierarchical
agglomerative models select prior candidate clusters, and the  nal number of clusters is
selected through selection criteria of models. In the second stage it is proposed the Poisson
model considering autoregressive conditional prioris, the clusters de ned in the  rst stage,
and also including covariates. This model  ll in the class of Gaussian latent models, therfore
its paremeters were estimated using bayesian inference, speci cally through integrated nested
Laplace approximation. Finally, as a result, we found clusters in accordance with the default
level, allowing to classify provinces into clusters of high, medium and low risk level.",2021-11-07
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Mixtura finita de una distribución Birnbaum-Saunders basado en la familia de mixtura en parámetros de escala de distribuciones normal asimétrica,"Gavidia Pucllas, Daniel Elías",Magíster en Estadística,"Benites Sánchez, Luis Enrique","The following thesis presents the  nite mixtures of Birbaums-Saunders distributions based
on the scale mixture of skew-normal distributions, which are called FM-BS-SMSN. This
model is an extension of Maehara (2018a) study of unimodal data based on scale mixture
of skew-normal distributions which are used to model extreme percentiles in the left-tail of
the distribution. The proposed model can  t two or more mixture of components of skewed
distributions like Skew-t, Skew-slash, and skew-contaminated normal. The proposed method
to accomplish the estimation of model parameters is the expectation of conditional maximization
(an extension of EM algorithm). Moreover, simulations and applications are presented
to illustrate the robustness of the proposed estimation method and standar errors. Finally,
the last chapter presents an aplication for real data sets.",2021-10-06
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Modelo de regresión no lineal basado en una mixtura de la distribución senh-normal/independiente en el error,"Ocampo Corrales, Carlos Iván",Magíster en Estadística,"Benites Sánchez, Luis Enrique","La distribución normal, si bien útil para explicar la distribución de muchos conjuntos
de datos, a veces es inadecuada para ello. En este sentido, en muchos casos es conveniente
trabajar con transformaciones de la distribución normal por ejemplo log-normal, Birnbaum-
Saunders (BS) y Senh-Normal (SN). En esta tesis se presenta un modelo de regresión no lineal
basado en una mixtura  finita de distribuciones Senh-Normal/Independiente (SNI) en el error
considerando dos casos específicos de esta distribución, SN y Senh-t-Student (SSt), respectivamente.
En el contexto de regresión se plantea una metodología de estimación mediante la
aplicación del algoritmo EM y también para el cálculo de los errores estándar.
Se realizaron estudios de simulación para evaluar las propiedades de las estimaciones. Los
resultados muestran que el modelo estima de manera satisfactoria los parámetros, más aún,
evaluando el sesgo y el RSME de las estimaciones se observa que el modelo cumple con las
propiedades asintóticas de los estimadores de máxima verosimilitud. Asimismo, se realizaron
estudios de aplicación tanto para el modelo SN como SSt.",2021-09-22
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Modelos de regresión a la media con efectos mixtos para variable respuesta semicontinua,"Bautista Bautista, Luis Alberto",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","En muchas situaciones se dispone de una variable aleatoria continua no negativa con
asimetría positiva que eventualmente podría tomar el valor cero. Datos de esta naturaleza son llamados semicontinuos o cero-inflacionados y fueron tradicionalmente modelados usando el modelo de regresión de dos partes propuesto por Duan et al. (1983). En este modelo la variable respuesta sigue una distribución mixta de probabilidades conformada por una distribución de Bernoulli y una distribución continua no negativa. Una versión longitudinal de este modelo de regresión, pero que apunta a explicar la media de la variable de respuesta, fue propuesto por Smith et al. (2017). Este modelo planteaba, para su componente continua de respuesta, una distribución Log Skew Normal. El objetivo de este trabajo es estudiar un modelo alternativo al de Smith et al. (2017), que llamaremos, en general, un modelo de regresión a la media con efectos mixtos para respuestas semicontinuas, pues plantea una parametrización que permite estimar e interpretar los efectos de un conjunto de covariables sobre la media de las respuestas y no sobre la media condicionada a valores positivos. A diferencia del modelo de Smith et al. (2017), que hace uso de la distribución Log Skew Normal cero-inflacionada, nosotros modelaremos la respuesta con una distribución Gamma Generalizada cero-inflacionada. Este modelamiento, como se muestra, permite capturar de manera flexible ciertas características de los datos de respuesta, tales como, la asimetría y el comportamiento de las colas. Los resultados del estudio de simulación para el nuevo modelo mostraron un adecuado desempeño en la recuperación de sus parámetros, donde para la estimación de estos utilizamos un enfoque bayesiano y el uso de métodos MCMC Hamiltonianos. Por último, los resultados de su aplicación en el estudio longitudinal del efecto que ciertas variables podrán ejercer sobre la media de los gastos en educación de los hogares en el Perú, mostraron un mejor ajuste a los datos respecto al modelo de Smith et al. (2017), en base a los criterios de información ampliamente aplicado y de validación cruzada de Leave-one-out.",2021-09-01
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Modelo de regresión lineal con censura basado en una distribución senh-normal/independiente: una perspectiva frecuentista,"Alonzo Huaman, Max Walter",Magíster en Estadística,"Benites Sánchez, Luis Enrique","In this thesis, the linear regression model for censored data is studied considering a sinhnormal
/ independent distribution for errors from a frequentist approach. This paper considers
the revision of the existing theory, the construction of the new model, estimation of parameters,
simulation studies to retrieve the parameters of the model and the application to a set
of real data.",2021-08-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Inferencia bayesiana en un modelo de regresión cuantílica autorregresivo,"Quintos Choy, Manuel Alejandro",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","El modelo de regresión cuantílica autorregresivo permite modelar el cuantil condicional
de una serie de tiempo a partir de los rezagos de la serie. En el presente trabajo se presenta
la estimación de este modelo desde la perspectiva bayesiana asumiendo que los errores se
distribuyen según la distribución asimétrica de Laplace (ALD). Luego, el proceso de generación de muestras de la distribución a posteriori es simplificado utilizando una representación estocástica de la ALD propuesta por Kotz et al. (2001) y el algoritmo de datos aumentados de Tanner y Wong (1987), siguiendo la propuesta de Kozumi y Kobayashi (2011), así como las adaptaciones para el modelamiento de series de tiempo de Cai et al. (2012) y Liu y Luger (2017). Los estudios de simulación demuestran que el supuesto sobre la distribución del término error no es limitante para estimar el cuantil condicional de series de tiempo con otras distribuciones. El modelo es aplicado en la predicción del Valor en Riesgo (VaR) en la serie de tiempo de los retornos diarios de la tasa de cambio de PEN a USD, y sus resultados son comparados con las predicciones obtenidas por las metodologías RiskMetrics, GARCH(1,1) y CAVIaR. Al respecto, la evidencia numérica permite concluir que el modelo QAR es una alternativa válida para estimar el VaR.",2021-06-14
Pontificia Universidad Católica del Perú. Escuela de Posgrado.,Modelo de regresión semiparamétrico robusto,"Esquivel Segura, Henry John",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","El presente trabajo de tesis presenta un modelo de regresión semiparamétrico con errores
t-Student, que permite estudiar el comportamiento de una variable dependiente dado un
conjunto de variables explicativas cuando los supuestos de linealidad y normalidad no se
cumplen. La estimación de los parámetros se realiza bajo el enfoque bayesiano a través del
algoritmo de Gibbs. En el estudio de simulación se observa que el modelo propuesto es más
robusto ante la presencia de valores atípicos que el usual modelo regresión semiparamétrico
normal. Asimismo se presenta una aplicación con datos reales para ilustrar esta característica.",2021-05-11
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo de regresión Dirichlet bayesiano: aplicación para estimar la prevalencia del nivel de anemia infantil en centros poblados del Perú,"Andrade Chávez, Francisco Mauricio",Magíster en Estadística,"Quiroz Cornejo, Zaida Jesús","La anemia es una afección causada por un bajo nivel de hemoglobina en la sangre causada
principalmente por un déficit en el consumo de hierro. En el Perú, es un problema de
salud pública y nutrición principalmente en niñas y niños menores de cinco años, por ello el
Instituto Nacional de Estadística (INEI) realiza una prueba para determinar anemia en niñas
y niños a través de la Encuesta Demográfica y de Salud Familiar (ENDES). En esta encuesta
se clasifica los niveles de anemia como severa si es menor a 7,0 g/dl, moderada si está entre
7,0 y 9,9 g/dl o leve si varía entre 10,0 y 11,9 g/dl. En este contexto, en esta tesis se propone
aplicar el modelo de regresión de Dirichlet para estimar la prevalencia de los niveles de
anemia infantil a nivel de centros poblados en el año 2017. Se propone estimar los parámetros
usando inferencia bayesiana, a través del método Halmitoniano de Monte Carlo (HMC) usando
Rstan. El modelo propuesto también permite identificar posibles factores determinantes
de la prevalencia de la anemia infantil y tiene el propósito de mejorar las políticas públicas
dirigidas a la reducción de la anemia en el país.",2021-03-29
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Endpoint-inflated beta-binomial regression for correlated count data,"Fazio Luna, Boris Manuel",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","The endpoint-inflated binomial regression model provides a way of modeling bounded
count data with a high proportion of observations at the endpoints. We extended the model
by considering an ordered logit link which exploits the natural ordering in the inflation
probabilities and explore the utility of random effects and marginalization for dealing with
repeated measures. We use a dataset previously analyzed in the literature with an endpointinflated binomial regression using a softmax link to show our model achieves an improved fit.",2021-03-29
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Aplicación del modelo de espacio de estados con errores correlacionados a la tasa de desempleo en Perú,"Visa Flores, Rafael",Magíster en Estadística,"Sikov, Anna","En este trabajo se presenta los modelos de espacio de estados con errores correlacionados,
propuesto por Pfeffermann y Tiller (2006), aplicado a datos reales de la tasa de desempleo
para Lima Metropolitana, cuya información es recolectada mediante la Encuesta Permanente
del Empleo - EPE por el Instituto Nacional de Estadística e Informática. Estos modelos
permiten dar tratamiento a series de tiempo con errores de medición correlacionados, la
estimación de los componentes del modelo se realiza mediante el algoritmo recursivo de
Pfeffermann y Tiller, y cuando los errores son independientes se utiliza el algoritmo recursivo
del filtro de Kalman. Se realizó un estudio de simulación con series de tiempo con errores correlacionados con
el objetivo de comparar las predicciones obtenidas con el algoritmo del filtro de Kalman y el
algoritmo de Pfeffermann y Tiller, resultando este último con menores errores de predicción. Con la finalidad de comparar la aplicación del modelo de espacio de estados con errores
correlacionados con una metodología muy conocida como el desarrollado por Box and Jenkins,
se ajustó los datos de la tasa de desempleo a un modelo ARIMA, se comparó las predicciones
de ambos modelos con las verdaderas observaciones, donde los errores de las predicciones
fueron similares, sin embargo, el menor error cuadrático medio se obtuvo con el modelo de
espacio de estados con errores correlacionados.",2021-02-25
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelamiento del tiempo a la ocurrencia de un evento con tiempos discretos,"Huertas Quispe, Anthony Enrique",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","En este trabajo de tesis, se plantea estudiar el tiempo a la ocurrencia de un evento en un proceso discreto. Para ello, se considera un modelo mixtura de fracción de cura sobre una población segmentada en dos tipos de individuos: sujetos curados, o también denominados sobrevivientes a largo plazo, haciendo referencia a aquellos sujetos que no alcanzarán el evento de interés en estudio; y sujetos no curados, o también denominados sujetos susceptibles, quienes en un tiempo específico, experimentarán dicho evento de interés. Los objetivos principales de esta tesis, son el de estimar la fracción de cura, la cual está definida como la proporción de individuos curados al final del estudio, y estimar el tiempo de falla para los individuos susceptibles, entendiéndose como el tiempo a la ocurrencia del evento. Este análisis se llevará a cabo con la presencia de covariables y datos censurados, siendo la simulación e inferencia de los datos efectuados vía el software estadístico R, en donde los procesos de simulación abordarán distintos escenarios para evaluar la performance del modelo propuesto.",2021-01-18
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Métodos de selección de variables bajo el enfoque bayesiano para el modelo lineal normal,"Blas Oyola, Sthip Frank",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","En muchos casos prácticos, al realizar un análisis de regresión, se cuenta con un gran
número de potenciales variables explicativas de las cuáles sólo algunas serán importantes para explicar la variable respuesta. Por lo tanto, un problema importante para la construcción de un modelo de regresión es encontrar un adecuado conjunto de variables explicativas. A los métodos que lidian con este problema se les denomina métodos de selección de variables. En el presente proyecto de tesis, se estudiarán tres métodos de selección de variables bajo inferencia bayesiana para el modelo de regresión lineal normal los cuales fueron propuestos por George y McCulloch (1993), Kuo y Mallick (1998) y Dellaportas et al. (2002). Estos métodos, a diferencia de los métodos tradicionales, consideran la selección de variables dentro del mismo modelo, por ejemplo, introduciendo variables latentes que indiquen la presencia o ausencia de una variable explicativa. Se realizaron comparaciones de estos métodos bayesianos con los métodos Lasso y Stepwise por ser los más tradicionales. A través de un estudio con datos simulados, en diversos escenarios se observa que los métodos bayesianos permiten una adecuada selección de las variables explicativas. Adicionalmente se presentan los resultados de una aplicación con datos reales.",2021-01-18
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Sistema de tarifación bonus-malus para la rama de seguros de automóvil,"Vivanco Ortiz, Yoshi Abel",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","En la actualidad, las empresas aseguradoras cuentan con productos de seguros
cada vez más personalizados a las características de sus asegurados, de modo que,
cada asegurado no pague el mismo monto de prima sino un monto proporcional a su
comportamiento y perfil de riesgo. Una de las formas de atender esta necesidad de
personalización en la tarifación es el Sistema Bonus-Malus (SBM), el cual ajusta una
prima base considerando la historia de siniestros reportados por cada asegurado. En
ese sentido, una historia sin siniestros crea bonificaciones (bonus) y por ende una
reducción en la prima de seguro; y, una historia con siniestros genera penalizaciones
(malus) y por ende un incremento en la prima de seguro. Por tanto, el objetivo de
esta tesis es aplicar los modelos SBM basados en la frecuencia para un seguro de
tipo vehicular. Para ello, en base a la información disponible de los asegurados, se
construye un modelo de frecuencia de siniestros usando un GLM (Poisson, Binomial
Negativa y sus variantes inflacionadas en ceros), cada modelo permite obtener
una prima base y clases de riesgo basados en características heterogéneas. Luego,
se comparan todos los modelos obtenidos para seleccionar el mejor ajuste para los
datos analizados. Por u´ltimo, se aplica el SBM y se determina en qué nivel se clasifica
a cada asegurado en función al número de siniestros que reporte en el periodo
de análisis, de esa manera, se determina el valor de la prima ajustada para cada
asegurado. En resumen, este trabajo desarrolla un SBM con información a priori y a
posteriori que permite obtener primas más justas para los asegurados de un producto
de seguros vehiculares, de modo que, el asegurado que presente un comportamiento
sin siniestros reportados pagará menos que un asegurado que presente siniestros en
el periodo evaluado.",2021-01-18
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo de supervivencia de larga duración con riesgos proporcionales y estimación del riesgo base vía splines: modelamiento de abandono de seguros,"Mattos Galarza, Hector",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","Survival models, those that are focused on trying to describe the time before the ocurrence of one
or more events, have demonstrated great versatility in their capacity to model various types of events
and a further reach than initially proposed. Its application encompasses from medical trials to uses in
financial activities like assets risk management, among others. This work focuses in the analysis of
the time of a customer until their decision of termination of an insurance policy. In this application,
only a fraction of the population are prone to terminate their contract and, in this sense, it is needed
that the model have a certain degree of flexibility of assuming that not all the clients are susceptible
to this event. A long-term proportional hazard model is proposed in this work with base risk function
modeled via monotone splines. This work starts with the model definition, the parameters estimation
process, simulation scenarios where the estimation and inference process performance is evaluated and
finally an application to study the associated factors with the churn process for an insurance company
in Perú.",2021-01-12
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Jointly modelling of cluster dependent pro les of fractional and binary variables from a Bayesian point of view,"Cortés Tejada, Fernando Javier",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","The following thesis proposes classi cation models that consist of jointly  tting longitudinal
pro les of mixed fractional and binary variables modelled by zero-one beta in
ated mixed
regressions with cluster formation. The distinct proposed parametrizations allow di erent effects
to be modelled, such as modelling the marginal mean directly through independent
variables and easily interpret its e ect on it or modelling the conditional mean and the in-

ation probabilities separately. In addition, individuals with similar fractional longitudinal
pro les are grouped into a cluster through a latent variable, assuming that the response variables
follow a  nite mixture model. Due to the complexity of the models, the parameters are
estimated from a Bayesian point of view by simulating a MCMC using JAGS software in R.
The proposed models are  tted in various simulated datasets and are compared against other
models to measure performance in  tting fractional longitudinal pro les and binary variables.
Finally, an application on real data is conducted, consisting on longitudinal information of
credit card utilization ratio and default status as dependants variables and covariates corresponding
to client information, aiming to obtain clusters of clients with similar behaviour in
evolution of credit card utilization and relate them to their probability of default.",2020-10-27
Pontificia Universidad Católica del Perú. Escuela de Posgrado,"Regresión espacial cuantílica para variables acotadas entre (0,1)","García Céspedes, Carlos Jeffer",Magíster en Estadística,"Quiroz Cornejo, Zaida Jesús","El Perú es un país emergente donde el desarrollo se centra en algunas ciudades y distritos específicos. Esto conlleva a mucha desigualdad económica por ello resulta importante dar seguimiento a la incidencia de pobreza en el país. De acuerdo al nivel de precariedad, la pobreza puede considerarse extrema o no extrema. En este contexto, estudiamos la incidencia de pobreza no extrema a través de un modelo de regresión cuantílica espacial a nivel distrital en la provincia de Lima utilizando la distribución de Kumaraswamy combinada con un efecto espacial intrínseco condicional autorregresivo (ICAR). Para tratar y evaluar la posible confusión espacial entre los efectos espaciales y las covariables de efectos fijos, se considera, también, el enfoque SPOCK (Spatial Orthogonal Centroid \K""orrection). Nuestros modelos pertenecen a la clase de modelos jerárquicos, para los cuales la inferencia se puede realizar utilizando el método de Monte Carlo Hamiltoniano. Por lo tanto, el modelo es computacionalmente factible para grandes conjuntos de datos, puede describir puntos extremos de la distribución de la incidencia de pobreza no extrema e identificar qué factores son importantes en las colas de la distribución de los datos.",2020-10-26
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Extensión al modelo DINA reparametrizado con covariable,"Sáenz Egúsquiza, Miguel Angel",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","En el campo educacional, cuando los estudiantes resuelven problemas su habilidad en un tema particular puede influir en el desempeño de los mismos en un área de estudio similar pero diferente. Por ejemplo, la habilidad en ciencias podría tener un efecto en su dominio sobre las matemáticas, lo que a su vez afectará la forma en que los evaluados responden a las preguntas o ítems sobre matemáticas de una prueba. Por tanto, resulta natural examinar la relación entre el rendimiento en un área particular de estudio y el dominio de los atributos en un tema relacionado. Los modelos de diagnóstico cognitivo (CDM) proporcionan un marco ideal para realizar un análisis de este tipo, ya que clasifican a los examinados en perfiles de atributos que indican su dominio en las habilidades delimitadas permitiendo obtener información más específica con respecto a sus fortalezas y debilidades. Los CDM resuelven varias limitaciones de los métodos clásicos y los modelos de teoría de respuesta a ítems unidimensionales (TRI).
Para este estudio se amplía el marco de DINA al incorporar una covariable en un modelo de DINA reparametrizado. La covariable se puede especificar en dos niveles: en el nivel inferior, afectando la forma en que los evaluados resuelven los ítems (es decir, la probabilidad de respuesta), y en el nivel superior, influenciando en el dominio de los atributos (es decir, la clasificación latente). En esta tesis, se desarrolla teóricamente el modelo indicado desde el enfoque clásico. Para la estimación desarrollaremos el método de máxima verosimilitud y el método de la moda a posteriori vía el algoritmo de Esperanza-Maximización (EM) y de Newton-Raphson. Para tal fin, se realiza 4 estudios de simulación con la finalidad de observar en primer lugar el efecto de la covariable cuando afecta simultáneamente a los ítems y a los atributos, luego cuando la covariable afecta por separado a ambos, y también cuando la covariable no los afecta. Finalmente, se muestra su aplicación en la evaluación de la prueba de admisión a una Universidad.",2020-10-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo bayesiano geoestadístico beta-inflacionado utilizando NNGP con aplicación a datos de cobertura forestal,"Barriga Pozada, Alfonso Carlos Cesar",Magíster en Estadística,"Quiroz Cornejo, Zaida Jesús","In this thesis, we propose a new geostatistical beta inflated zero-one model using
NNGP (Nearest Neighbor Gaussian Process). The main advantage of using NNGP in
the modeling of spatial effects is the reduction of the large computing time it takes to
model a Gaussian process since it does not need to work with all the neighbors, but
only with a small group. The estimation of the parameters is done from a bayesian
perspective since the posterior distribution does not have a known shape. In addition,
a simulation studywas carried out inwhich testswere donewith different amounts of
neighborstoevaluateintermsofRMSEandcomputational timethegaininthemodels
whenaddingmore neighbors.Finally, the proportionof forest cover inHiroshimawas
modeled using the developed geostatistical model, obtaining good results.",2020-09-29
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo lineal mixto de clases latentes con respuesta ordinal y su aplicación en la medición de la religiosidad,"Renteria Sacha, Ivonne Mireille",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","Latent class linear mixed models developed by Proust-Lima, Philipps y Liquet (2017) are useful to analyze the dynamic aspect and the multidimensional nature of a phenomenon of interest in populations not necessarily homogeneous. These allow to identify the possible latent classes in the population under study and how a set of covariates affects the response variable of interest in each class. In this thesis, the latent class linear mixed model with latent response variable and ordinal manifest variable is developed, through its two components: the structural sub-model and the measure sub-model, which are complemented with a mul-tinominal logistic model to analyze the probability of belonging to a latent class. The model was applied to a dataset from the National Study of Youth and Religion (NSYR), in order to find latent classes in the religiosity construct and to describe their evolution. As a result, three latent classes were identified with different trajectories for each case.",2020-01-16
Pontificia Universidad Católica del Perú. Escuela de Posgrado,El Modelo de Respuesta Nominal: Aplicación a datos educacionales,"Rivera Espejo, José Manuel",Magíster en Estadística,"Tarazona Vargas, Enver Gerald","This thesis focuses its e orts on presenting and studying the Nominal Response Model
or NRM (Bock, 1972, 1997), in the context of the Item Response Theory (IRT). Simulation
studies are carried out to determine the quality of the recovery of the parameters of the
model, under the Classic (MML) and Bayesian (MCMC) aproach and  nally, the studied
model was applied to an random, representative and anonymous sample of 1641 teachers
from the Basic Regular Education modality of the english specialty, who were exposed to the
Reading-Comprehension sub-test of the \Concurso de Nombramiento 2015"".
Related to the simulation, we found the bayesian method is a good substitute for the
classic counterpart, because it recovers in a similarly satisfactory fashion the parameters of
the items; however, the main disadvantage was that the process was between 620 to 14; 100
times slower than the classical approach, despite the special emphasis on making the MCMC
processes parrallel.
Related to the results of the implementation of the model on real data, the NRM: (i) it
facilitates the recovery of a greater proportion of information available in the items, compared
to dichotomous response models (Bock, 1972; Thissen, 1976; Levine y Drasgow, 1983;
Thissen y Steinberg, 1984), (ii) it allows to  nd the implicit order in initially not ordered
categorical data (Samejima, 1988; Bock, 1997) and (iii) it provided relevant information for
the examination of the quality of an item (Thissen et al., 1989), specially in two fronts: (a) it
allowed the identi cation of useless or forced alternatives and (b) it allowed the identi cation
of alternatives that could be collapsed, given that these alternatives registered a similar topics.</td><td></td>
</tr>
<tr class=""ds-table-row even "">
<td class=""label-cell"">dc.description.abstract</td><td class=""word-break"">La presente tesis centra sus esfuerzos en presentar y estudiar el Modelo de Respuesta
Nominal o NRM por sus siglas en inglés (Bock, 1972, 1997), en el contexto de la Teoría de Respuesta al ítem (IRT, por sus siglas en inglés). Se realizaron estudios de simulación para determinar la calidad de la recuperación de los parámetros del modelo, bajo la metodología clásica (MML) y bayesiana (MCMC) y finalmente, se aplicó el modelo estudiado en una muestra anónima, aleatoria y representativa de 1641 docentes de la modalidad de Educación Básica Regular de la especialidad de inglés, que fueron expuestos a la sub-prueba de Compresión Lectora del Concurso de Nombramiento 2015.
En relación a la simulación, encontramos que el método bayesiano es un buen sustituto de su contraparte clásica, debido a que el mismo recupera de manera similarmente satisfactoria los parámetros de los ítems; sin embargo, la principal desventaja es que fue entre 620 a 14100 veces más lento que los métodos clásicos, pese a que se puso especial énfasis en hacer paralelos los procesos MCMC.
En relación a los resultados de la aplicación se tiene que el NRM: (i) facilita la recuperación de una mayor proporción información disponible en los ítems, frente a los modelos de respuestas dicotómicas (Bock, 1972; Thissen, 1976; Levine y Drasgow, 1983; Thissen y Steinberg, 1984), (ii) permite hallar el ordenamiento implícito en datos categóricos inicialmente no ordenados (Samejima, 1988; Bock, 1997) y (iii) brinda información relevante para la valoración de la calidad de un ítem (Thissen et al., 1989), especialmente en dos puntos: (a) les permitía identificar alternativas inservibles o forzadas y (b) les permita identificar alternativas que se podían colapsar, dado que estas alternativas registraban similar temática.",2019-07-17
Pontificia Universidad Católica del Perú. Escuela de Posgrado,El modelo de larga duración Weibull-Geométrica,"Torres Salinas, Karina Hesi",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","Los modelos de larga duración son una extensión de los modelos de supervivencia tradicional
y nos permiten modelar una proporción de la población que no llegan a experimentar
un evento de interés, incluso después de un largo periodo de seguimiento. En este trabajo
se presenta y deduce la distribución de larga duración Weibull-Geométrica y su proceso de estimación e inferencia. Se desarrolló un estudio de simulación con el un de evaluar el desempeño de las estimaciones y determinar si se recuperan los parámetros. Asimismo el modelo fue aplicado a una muestra de clientes que adquirieron y activaron una tarjeta de crédito
entre enero a diciembre del año 2015 y donde el principal objetivo del análisis era entender el
comportamiento del tiempo hasta la cancelación de la tarjeta de crédito del cliente. Comparamos
al modelo de larga duración Weibull-Geométrica con otros modelos de larga duración,
Exponencial-Geométrica y Weibull. Los resultados indican que nuestro modelo muestra un
mejor ajuste en los datos.",2019-03-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo G-DINA aplicado al diagnóstico de desórdenes mentales,"Villena Guzmán, Denisse",Magíster en Estadística,"Tarazona Vargas, Enver Gerald","Actualmente, uno de los modelos de diagnóstico cognitivo (MDC) más usados es el modelo
DINA. Sin embargo, este modelo presenta varias restricciones que hacen que en muchas
ocasiones, no sea el que mejor se ajusta a la realidad. En ese contexto, nace una generalización
del modelo DINA, denominado G-DINA (Generalized deterministic input, noisy and gate).
En el presente estudio se presentan los fundamentos y propiedades del modelo G-DINA y
su aplicación en un área en el que su uso todavía no es muy común: la psicología. Así, se
evaluaron los resultados de una muestra de pacientes de un hospital general de Lima a los
que se les aplicó el test SRQ-18 que evalúa la presencia de desórdenes mentales. Se muestra
el proceso de selección del mejor modelo para cada ítem, los resultados de los parámetros
obtenidos, los diagnósticos para los 10 primeros pacientes y una distribución de los perfiles
de estos pacientes. Finalmente se presenta un estudio de simulación que tiene por finalidad
estudiar el efecto del tamaño de muestra en la estimación de los parámetros en el contexto
de la aplicación de este estudio.",2019-02-11
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Análisis bayesiano de modelos de clases latentes para variables politómicas: Confianza hacia instituciones públicas,"Cruz Sarmiento, Marylía Paola",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","El modelo de análisis de clases latentes tiene como  finalidad describir una variable no observable a través del agrupamiento de los individuos en base a sus patrones de respuestas.
La estimación en este modelo se puede realizar mediante el algoritmo de Esperanza-Maximización (EM) y su desarrollo para el caso politómico se encuentra implementado en el paquete poLCA de R. Desde el punto de vista bayesiano, esta estimación ha sido hasta el momento implementada sólo para el caso de variables dicotómicas. En este trabajo, se busca
extender este  ultimo aporte para el caso politómico, haciendo uso del muestrador de Gibbs.
La aplicación del modelo de análisis de clases latentes, bajo el enfoque bayesiano aquí desarrollado, se realizó sobre un conjunto de datos reales relacionados con la con fianza hacia 21 instituciones públicas en una encuesta para Lima Metropolitana. En general, se identificaron tres grupos de encuestados seg un sus niveles de confianza institucional, los cuales se analizaron luego en relación a otras variables.",2019-02-11
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo secuencial con aplicación a la medición del rendimiento estudiantil,"Mejía Campos, Luis Ángel",Magíster en Estadística,"Tarazona Vargas, Enver Gerald","En este trabajo se presenta el Modelo Secuencial para datos politómicos ordinales de la
teoría de respuesta al ítem y sus características. De forma específi ca se estudia el Modelo
Secuencial Logístico de 2 parámetros (2PL-SM). La estimación de este modelo se realiza
utilizando Métodos de Cadenas de Markov de Montecarlo (MCMC), los cuales fueron implementados
en R y WinBUGS.
Se realizó un estudio de simulación con el objetivo de estudiar la precisión en la recuperación de parámetros observándose resultados apropiados según los índices de precisión
utilizados.
El Modelo Secuencial en estudio fue luego aplicado a la prueba de escritura de la Evaluación Muestral 2013 del Ministerio de Educación, evaluación que fue aplicada a una muestra
de 4327 estudiantes de sexto grado de primaria de todo el país. Con la aplicación del modelo a
la prueba se pudo determinar que en general esta contiene ítems cuyas di ficultades son bajas
y que, para los estudiantes, el enfrentarse a esta prueba no debería resultarles complicado.",2019-02-04
Pontificia Universidad Católica del Perú. Escuela de Posgrado,El modelo de larga duración Exponencial-Poisson,"Gonzales Rodriguez, Julia Elena",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","In this thesis the long-term survival model Exponential-Poisson will be introduced and
discussed. This model allows to study the time until the occurrence of an event of interest
when it is assumed that there is a fraction of the population that is immune to the occurrence
of this event. The studied model is a mixture model that assumes that the time to the event
among susceptible follows a Exponential-Poisson distribution and that the probability of
being inmune to the event of interes is explained by a set of covariates via a logistic regression
model. A simulation study was carried out in which the good performance of the model was
checked through the percentage bias and 95% coverage. Finally, the model is applied to a
sample of a Peruvian  nantial entity where the event of interest is the cancellation of the
debt.",2018-12-03
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo de regresión a la media simplex inflacionada para proporciones,"Chámpac Flores, Juan Carlos",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","El presente trabajo de tesis propone el modelo de regresión a la media simplex inflacionada,
que permite modelar variables aleatorias continuas limitadas en el intervalo cerrado [0; 1]
al considerar un conjunto de ecuaciones de regresión para estimar la media de la respuesta
y los parámetros que modelan las probabilidades de los valores extremos 0 y 1. Asimismo,
se desarrolla un estudio de simulación con el  fin de evaluar si el método propuesto permite
recuperar los parámetros del modelo desde el punto de vista de la estadística clásica. Por
otro lado, se desarrolla la aplicación del modelo para determinar el grado de dolarización
de empresas que registran deudas en el Sistema Financiero, y para evaluar el desempeño del
mismo, se compara contra el modelo de regresión a la media beta inflacionada. Los resultados
muestran un mejor ajuste del modelo propuesto en esta tesis.",2018-11-15
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos de regresión gamma generalizada cero-inflacionada para la media con aplicación a gastos en educación,"Vásquez Beltrán, Aníbal Alcides",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","Cuando los valores posibles de una variable aleatoria son continuos y no negativos, incluyendo
el valor cero con probabilidad no nula, la variable es denominada semicontinua o
cero-in acionada y posiblemente sea pertinente suponer que presenta una distribución mixta
de probabilidades constituida por una distribución de Bernoulli para explicar si la respuesta
toma el valor cero o no y una distribución continua positiva para explicar si ésta última
no es cero. En el análisis de regresión, el modelo de dos partes (MDP) es tradicionalmente
usado para explicar una variable semicontinua. En el MDP la respuesta presenta este tipo
de distribución mixta y sus parámetros son expresados de tal manera que posibilite estimar
el efecto de un conjunto de covariables sobre la media de esta respuesta condicionada a que
tome valores positivos y sobre la probabilidad de que la respuesta tome el valor cero.
El objetivo de la tesis es estudiar un modelo alternativo al MDP, que llamaremos modelo
de regresión cero-in acionada a la media (MCIM), cuya parametrización permita estimar e
interpretar efectos de covariables sobre la media total de la respuesta, en lugar de la media
condicionada a valores positivos. Además, optamos por la distribución gamma generalizada
(MCIM-GG) para modelar ciertas características de los valores positivos de la respuesta, tales
como, por ejemplo, la asimetría positiva y la curtosis pronunciada. Estas características, junto
con el exceso de valores cero, son típicas en diferentes ejemplos de variables respuestas en la
Economía y la Medicina.
Los resultados del estudio de simulación muestran un adecuado desempeño de las estimaciones
de máxima verosimilitud del MCIM-GG bajo diferentes escenarios de nidos según
porcentajes de valores ceros de la respuesta y tamaños de muestra. Por último, los resultados
de la aplicación muestran que el MCIM-GG puede tener un mejor ajuste a los datos respecto
al MDP-GG, así como proporcionar una más directa interpretación de los efectos de ciertas
covariables sobre la media de los gastos en educación de adolescentes participantes del estudio
Niños del Milenio en el Perú.",2018-11-13
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo lineal mixto conjunto de clases latentes aplicado a un conjunto de datos longitudinales del sector salud,"Neciosup Vera, Carmen Stéfany",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","The joint latent class mixed model, proposed by Proust-Lima et al. (2015), allows to
jointly model a longitudinal process and a survival process, also calculating the probability
of belonging to certain latent classes in the study population. In our study, we describe the
components that make up this model (Proust-Lima et al. (2017)) and through a simulation
study we assesed the implementation of its estimation. The model is finally applied to a set of
longitudinal data of Prostate Cancer diagnosed patients allowing us to identify latent classes
that are then associated with the clinical stage of the patients.",2018-11-13
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Análisis de influencia bajo inferencia bayesiana en evaluaciones escolares de altas consecuencias,"Christiansen Trujillo, Andrés Guillermo",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","La presente investigación estudia una metodología para la detección de observaciones atípicas mediante un análisis de influencia bajo la perspectiva de la inferencia bayesiana. Se utiliza la medida de phi-divergencia y el estimador de Monte Carlo, derivado de ésta, trabajados previamente por Peng y Dey (1995), para el cálculo de las divergencias Kullback-Leibler, distancia rectilínea y ji-cuadrado. Además, en el presente trabajo se busca realizar este análisis de influencia en evaluaciones de altas consecuencias (evaluaciones cuyos resultados tienen un alto impacto en la vida de los estudiantes o docentes). El estudio de simulación revela que es posible recuperar observaciones previamente distorsionadas como atípicas. Finalmente, se aplica la metodología a una evaluación realizada por el Ministerio de Educación. Esta aplicación revela que la metodología estudiada es capaz de identificar escuelas con resultados no esperados dadas sus condiciones y resultados anteriores.",2018-07-30
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Inferencia bayesiana en el modelo de regresión beta rectangular,"Calderón Pozo, Francisco German",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","Se conoce que el modelo lineal normal no es apropiado para situaciones en la que la variable respuesta es una proporción que solo toma valores en un rango limitado (0; 1), pues, se pueden obtener valores ajustados para la variable de inter es que exceden sus límites inferior y superior.
Ante dicha situación, una propuesta es utilizar la distribución beta ya que es bastante flexible para modelar proporciones. Este modelo de regresión, sin embargo, puede ser influenciado por la presencia de valores atípicos o extremos. Debido a ello, se ha propuesto en la literatura, un modelo de mayor robustez llamado modelo de regresión beta rectangular, el cual permite una mayor incidencia de tales valores.
El objetivo general de la tesis es estudiar las propiedades, estimar y aplicar a un conjunto de datos reales el modelo de regresión beta rectangular desde el punto de vista de la estadística bayesiana.
Para cumplir con el objetivo planteado, se estudian las características y propiedades de las distribuciones beta y beta rectangular. Luego, se desarrolla el análisis bayesiano del modelo de regresión beta rectangular considerando las distribuciones a priori y a posteriori, los criterios de selección de modelos y simulaciones de Montecarlo v  a cadenas de Markov. También, se realizan estudios de simulación para demostrar que el nuevo modelo es m as robusto que el modelo de regresión beta. Adicionalmente, se presenta una aplicación para mostrar la utilidad del modelo de regresión beta rectangular.",2018-05-07
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Estimación bayesiana de efectos de red: el modelo Logit mixto,"Chahuara Vargas, Paulo Roberto",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","Los efectos o externalidades de red son factores que pueden condicionar las decisiones de contratación de los consumidores en favor de empresas ya establecidas y en contra de los nuevos competidores, pudiendo limitar la competencia efectiva y potencial de los mercados, en especial, en aquellas industrias donde el número de empresas es bajo y la entrada de nuevos competidores es poco frecuente. Por ello, es importante verificar su existencia y la magnitud de sus efectos sobre las decisiones de compra de los consumidores con el objetivo de justificar o establecer medidas que impulsen una competencia más equilibrada entre las empresas. Además, teniendo en consideración que los consumidores pueden tener cierto grado de heterogeneidad en sus comportamientos de adquisición, también resulta relevante estudiar el grado de diferenciación de los efectos de red entre los consumidores a fin de mejorar las políticas que fomenten la competencia. Este trabajo tiene por objetivo estimar un modelo logit mixto bajo el enfoque de la inferencia bayesiana, para estudiar empíricamente la existencia y heterogeneidad de los efectos de red sobre las decisiones de contratación de los consumidores en la industria de telefonía móvil peruana. El análisis se hace con base a una muestra que combina información de la Encuestas Residencial de Servicios de Telecomunicaciones (ERESTEL) del a˜no 2015 e información de las empresas operadoras del servicio de telefonía móvil. Los resultados de las estimaciones realizadas sugieren que los efectos de red tendrían un condicionamiento importante sobre las decisiones de contración del servicio de telefonía móvil, además de presentar un grado de heterogeneidad estadísticamente significativo en la magnitud de sus efectos.",2017-10-02
Pontificia Universidad Católica del Perú. Escuela de Posgrado,A beta inflated mean regression model with mixed effects for fractional response variables,"Fernández Villegas, Renzo",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","En este artículo proponemos un nuevo modelo de regresión con efectos mixtos para variables acotadas fraccionarias. Este modelo nos permite incorporar covariables directamente al valor esperado, de manera que podemos cuantificar exactamente la influencia de estas covariables en la media de la variable de interés en vez de en la media condicional. La estimación se llevó a cabo desde una perspectiva bayesiana y debido a la complejidad de la distribución aumentada a posteriori usamos un algoritmo de Monte Carlo Hamiltoniano, el muestreador No-U-Turn, que se encuentra implementado en el software Stan. Se realizó un estudio de simulación que compara, en términos de sesgo y RMSE, el modelo propuesto con otros modelos tradicionales longitudinales para variables acotadas, resultando que el primero tiene un mejor desempeño. Finalmente, aplicamos nuestro modelo de regresión Beta Inflacionada con efectos mixtos a datos reales los cuales consistían en información de la utilización de las líneas de crédito en el sistema financiero peruano.",2017-06-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo Dina aplicado a la evaluación de matemática en estudiantes de segundo grado de secundaria,"Sosa Paredes, Yuriko Kirilovna",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","Los modelos de diagnóstico cognitivo (MDC) tienen como finalidad describir o diagnosticar el comportamiento de los evaluados por medio de clases o perfiles latentes, de tal manera que se obtenga información más específica acerca de las fortalezas y debilidades de ellos.

Uno de los modelos más populares de esta gran familia es el llamado modelo DINA, el cual tuvo su primera aparición en Haertel (1989) enfocado principalmente en el campo educacional. Este modelo considera solo respuestas observadas dicotómicas de parte de los individuos y tiene como restricción principal que ellos deben dominar necesariamente todas las habilidades requeridas por cada ítem; aquellas que se resumen en una matriz llamada Q. Asimismo, el modelo estima parámetros para los ítems, los cuales son denominados de \ruido"": Adivinación y Desliz.

En este trabajo desarrolla teóricamente el modelo expuesto; es decir, sus fundamentos y principales propiedades desde el enfoque bayesiano. Específicamente, las estimaciones se realizan mediante el Muestreador de Gibbs.

Se realizaron 8 estudios de simulación, cada uno de ellos con tres diferentes tamaños de población, donde se probaron combinaciones de los parámetros en estudio con el fin de comparar la recuperación de parámetros mediante el enfoque clásico y el bayesiano. El análisis de ambos enfoques se realizó con rutinas de código del software libre R, usando los paquetes CDM y dina para el enfoque clásico y el bayesiano, respectivamente.

En líneas generales, los resultados muestran estimaciones insesgadas y con valores pequeños de la raíz del error cuadrático medio (RMSE) para ambos enfoques. Incluso, conforme el tamaño de la población incrementa, las estimaciones no tienen mayores diferencias. Aunque en tamaños de población más pequeños el enfoque bayesiano obtiene ligeras ventajas con respecto al otro, especialmente en el parámetro de probabilidad de pertenencia a las clases (π). Además, es necesario mencionar que los parámetros de ruido de los ítems son estimados más precisamente con el enfoque clásico en varios de los estudios. 

Finalmente, se presenta una aplicación enfocada en educación, donde se analiza una muestra de 3040 alumnos del 2do grado de secundaria, evaluados en una prueba de 48 ítems de la competencia matemática realizada por la Oficina de Medición de la Calidad de los Aprendizajes (UMC) en el 2015. A esta prueba se le aplica el modelo de Rasch y el modelo DINA bajo el enfoque bayesiano, con el _n de estudiar la correspondencia entre indicadores de ambos modelos, tanto para los parámetros de los alumnos (habilidad y per_les latentes) como de los ítems (dificultad y parámetros de ruido).",2017-05-31
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Estimation of the disease prevalence when diagnostic tests are subject to classification error: bayesian approach,"Gutiérrez Ayala, Evelyn Patricia",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","La estimación de la prevalencia de una enfermedad, la cual es definida como el número de casos con la enfermedad en una población dividida por el número de elementos en ésta, es realizado con gran precisión cuando existen pruebas 100% exactas, también llamadas gold standard. Sin embargo, en muchos casos, debido a los altos costos de las pruebas de diagnóstico o limitaciones de tecnología, la prueba gold standard no existe y debe ser reemplazada por una o más pruebas diagnósticas no tan caras pero con bajos niveles de sensibilidad o especificidad. Este estudio está enfocado en el estudio de dos enfoques bayesianos para la estimación de prevalencia cuando no es factible tener resultados de una prueba 100% exacta.
El primero es un modelo con dos parámetros que toman en cuenta la asociación entre los
resultados de las pruebas. El segundo es un enfoque que propone el uso del Bayesian Model Averaging para combinar los resultados de cuatro modelos donde cada uno de estos tiene suposiciones diferentes sobre la asociación entre los resultados de las pruebas diagnósticas.
Ambos enfoques son estudiados mediante simulaciones para evaluar el desempeño de estos bajo diferentes escenarios. Finalmente estas técnicas serán usadas para estimar la prevalencia de enfermedad renal crónica en el Perú con datos de un estudio de cohortes de CRONICAS (Francis et al., 2015).",2017-02-02
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos de teoría de respuesta al ítem multidimensional con una aplicación psicológica,"Malaspina Quevedo, Martín Ludgardo",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","La presente investigación, dentro del contexto de la Teoría de Respuesta al Ítem (TRI), estudia un modelo multidimensional logístico compensatorio de dos parámetros (M2PL) para ítems dicotómicos. Para ello, se explican teóricamente los métodos de estimación más conocidos para los parámetros de los ítems y de los rasgos latentes de las personas, priorizando el método bayesiano mediante Cadenas de Markov de Monte Carlo (MCMC). Estos métodos de estimación se exploran mediante implementaciones computacionales con el software R y R2WinBUGS. La calidad de las respectivas estimaciones de los parámetros se analiza mediante un estudio de simulación, en el cual se comprueba que el método de estimación más robusto para el modelo propuesto es el bayesiano mediante MCMC. Finalmente, el modelo y el método de estimación elegidos se ilustran mediante una aplicación que usa un conjunto de datos sobre actitudes hacia la estadística en estudiantes de una universidad privada de Colombia.",2016-11-23
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Combinación de reglas de portafolio con la asignación 1/N y la ponderada por capitalización bursátil,"Rodríguez Alcócer, Augusto Fernando",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","La teoría del portafolio estudia el proceso a través del cual se realiza la asignación óptima de activos. El análisis Media - Varianza (MV) propone que los agentes estructuran portafolios de inversión optimizando el retorno esperado o el riesgo. Así, fijando el nivel deseado de una de estas variables, es posible elaborar una frontera eficiente compuesta por portafolios óptimos. Sin embargo, si bien el análisis MV ha sido trabajado de manera extensa presenta una limitación: los parámetros reales no son conocidos sino estimados a partir de la observación de datos. Ello incorpora el problema de incertidumbre en la modelación, por lo que las reglas de portafolio óptimo están sujetas a errores aleatorios que pueden generar que los parámetros estimados se alejen de los reales. El objetivo del presente trabajo es revisar dicho análisis bajo el enfoque de reglas de portafolio, y si existe la posibilidad de reducir el riesgo de estimación a través de la combinación de las reglas con el portafolio de pesos iguales y con el portafolio ajustado por capitalización bursátil. Para la programación se utiliza el paquete estadístico R - project. Los resultados sugieren que la combinación de las reglas con los dos portafolios seleccionados puede mejorar los resultados fuera de muestra esperados y que bajo ciertas circunstancias, combinar con el portafolio de capitalización bursátil puede ser más eficiente que con el portafolio de pesos iguales.",2016-11-23
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Estudio de tres propuestas de distribución skew-t,"Kantor Benavides, Alejandro",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","Este trabajo compara tres distribuciones skew-t. En particular, las propuestas por Branco y Dey (2001) y Azzalini y Capitanio (2003), Fernández y Steel (1998), y Jones y Faddy (2003).
Se analiza la relación entre los parámetros y el nivel de asimetría a través de la medida de Patil et al. (2014). Se propone una nueva parametrización de la distribución skew-t de Jones y Faddy (2003) que modela mejor la asimetría. Las distribuciones son ajustadas a datos reales basados en el retorno logarítmico de la tasa de cambio de PEN a USD.",2016-06-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo de regresión de clases latentes: factores asociados a la valoración de una universidad privada,"Wiener Ramos, Lucia",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","En diversos campos de análisis, especialmente en las ciencias sociales y humanas, se identifican constructos teóricos a los cuales queremos aproximarnos pero que no son directamente observables ni medibles, como por ejemplo, la calidad o satisfacción con un servicio, el nivel de  estrés, el nivel de conocimiento en matemáticas, entre otras. Este tipo de constructos son llamados variables latentes y su valor solo puede ser aproximado a través de variables observadas o manifiestas que si pueden ser medidas (Bartholomew et al., 2011).
En el Capítulo 2 se presenta consideraciones generales acerca del modelo lineal general de variables latentes y el modelo de clases latentes. En el Capítulo 3 se estudian los modelos de regresión de clases latentes, la estimación de sus parámetros y su implementación computacional. En el Capítulo 4 se presenta los resultados de la aplicación del modelo a un conjunto de datos reales orientados a conocer la valoración de una universidad privada. En el Capítulo 5 se presenta algunas conclusiones, recomendaciones y futuras extensiones que se podrían derivar de este trabajo.",2016-06-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,An application of discrete time survival models to analyze student dropouts at a private university in Peru,"Pebes Trujillo, Miguel Raúl",Magíster en Estadística,"Sal y Rosas Celi, Víctor Giancarlo","Discrete-time survival models are discussed and applied to the study of which factors
are associated with student dropouts at a private university in Lima, Per_u. We studied the characteristics of 26; 790 incoming students enrolled between 2004 and 2012 in all the under-graduate programs at the University. The analysis include the estimation of the survival and hazard functions using the Kaplan-Meier method and the _tting of parametric models using the Cox proportional hazards regression and the Logistic regression for survival analysis, this last one, in order to include time varying variables as predictors. During the period of analysis, the cumulative probability of remain at the University after _ve years was 73.7% [95% CI: 73.1% - 74.4%]. In any period the hazard is greater than 4.4% and this highest value is reached in the 3rd semester. In a multivariate analysis, we found that academic factors (area of study, type of admission, standardized academic performance index, and the percentage of passed credits); economic factors (type of residence, and payment scale); and sociodemographic factors (mother education level, indicators of whether or not parents are alive, and the age of the student) were associated with the risk of dropout.",2016-06-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Una aplicación de la regresión de Cox con puntos de cambio en las covariables,"Trujillo Angeles, Lucía Inés",Magíster en Estadística,"Doig Camino, Elizabeth","El siguiente trabajo de tesis, estudiará el modelo de regresión de Cox con puntos de cambio en las covariables propuesto por Jensen y Lutkebohmert (2008), realizando el desarrollo y la aplicación para una base de líneas móviles postpago. El objetivo es obtener los parámetros de las covariables y el nuevo parámetro en el modelo que es el punto de cambio, para analizar la manera como estas covariables tienen influencia en la desactivación de una línea a solicitud del cliente.",2016-06-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos Chain Ladder estocásticos y aplicaciones al cálculo de reservas en compañías de seguros,"Mazuelos Vizcarra, Gisella Gabriela",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","El presente documento tiene por objetivo profundizar en el estudio de los m´etodos univariados
y multivariados del modelo Chain Ladder para la estimaci´on de las reservas de una
compa˜n´ıa de seguros. Se presenta de manera te´orica y aplicativa tanto los m´etodos univariados
Chain Ladder determin´ıstico como Chain Ladder estoc´astico. Si bien el primero de
estos m´etodos es el m´as utilizado por las compa˜n´ıas de seguro dada su simplicidad de c´alculo
y carencia de supuestos probabil´ısticos, el segundo, propuesto por Mack (1993), permite la
construcci´on de intervalos de confianza para las reservas, lo cu´al es de invalorable ayuda para
los investigadores.
Asimismo, desarrollamos el modelo General Multivariado Chain Ladder, el cual tiene
como premisa b´asica analizar la posible relaci´on que pueda existir entre diversos tri´angulos
de desarrollo, dotando as´ı de otra herramienta para mejorar las inferencias y predicciones de
las reservas.
Estos m´etodos han sido desarrollados y aplicados sobre la base de datos de 3 tipos de
seguros de salud, mostrando as´ı las ventajas y desventajas de cada uno de ellos en diferentes
escenarios y proporcionando distintos instrumentos para la toma de decisiones relacionados
en el cumplimiento de las obligaciones futuras de las compa˜nias de seguros.",2015-07-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos alternativos de respuesta graduada con aplicaciones en la calidad de servicios,"Tarazona Vargas, Enver Gerald",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","Los modelos politómicos de la Teoría de Respuesta al Ítem (TRIP) tienen como finalidad explicar la interacción existente entre los sujetos evaluados y los atributos de un test en aquellas situaciones en las cuales los atributos que lo componen tienen varias categorías de respuesta. Dentro de los distintos tipos de modelos TRIP, el Modelo de Respuesta Graduada General (GRM) propuesto originalmente por Samejima (1969, 2010), es un conjunto de modelos diseñados para aplicarse en aquellas situaciones en las cuales las categorías de respuesta son ordinales.
En este trabajo se presenta una formulación general para los GRM, su clasificación y
principales propiedades desde el punto de vista bayesiano. De manera específica, se muestra el Modelo de Respuesta Graduada Logístico de dos parámetros (2PL-GRM) como un caso particular de los GRM simétricos y el Modelo de Respuesta Graduada Logístico de Exponente Positivo (LPE-GRM) como un modelo asimétrico derivado de incorporar un parámetro de penalización que controla la curvatura de las Funciones de Respuesta a las Etapas de los Ítems (FREI). La estimación de ambos modelos fue realizada usando la inferencia bayesiana con Métodos Montecarlo vía Cadenas de Markov (MCMC) e implementada en R y WinBUGS.
Se realizó un estudio de simulación con el _n de estudiar la precisión en la recuperación de parámetros para el Modelo 2PL-GRM obteniéndose resultados apropiados para las medidas
de ajuste consideradas.
Los modelos 2PL-GRM y LPE-GRM estudiados fueron aplicados al estudio de un cuestionario acerca de la satisfacción de clientes y comparados con el tradicional análisis clásico de los test. La muestra del estudio está formada por 5354 clientes de una empresa de telecomunicaciones que se comunicaron con el Call Center de atención al cliente por algún motivo (consulta, reclamo, pedido, etc.). A través del análisis de dimensionalidad de la escala se encontró que el cuestionario evalúa dos dimensiones de la satisfacción con la atención al cliente: la Accesibilidad (4 ítems) y el Desempeño del asesor (7 ítems). Los resultados indican, considerando diferentes criterios, que en ambas dimensiones el modelo LPE-GRM es mejor.
Adicionalmente, ambos modelos ofrecen mejor información que el tradicional análisis clásico.
Se sugiere realizar diferentes estudios de simulación para evaluar distintas condiciones para la inferencia del modelo LPE-GRM puesto que para las mismas condiciones de estimación MCMC se observa que puede ser más demorado debido a que presenta mayor autocorrelación que el modelo 2PL-GRM.",2015-07-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Inferencia bayesiana en un modelo de regresión cuantílica semiparamétrico,"Agurto Mejía, Hugo Miguel",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","Este trabajo propone un Modelo de Regresión Cuantílica Semiparamétrico. Nosotros empleamos la metodología sugerida por Crainiceanu et al. (2005) para un modelo semiparamétrico en el contexto de un modelo de regresión cuantílica. Un enfoque de inferencia Bayesiana es adoptado usando Algoritmos de Montecarlo vía Cadenas de Markov (MCMC).
Se obtuvieron formas cerradas para las distribuciones condicionales completas y así el algoritmo muestrador de Gibbs pudo ser fácilmente implementado. Un Estudio de Simulación es llevado a cabo para ilustrar el enfoque Bayesiano para estimar los parámetros del modelo. El modelo desarrollado es ilustrado usando conjuntos de datos reales.",2015-07-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Portafolios óptimos bajo estimadores robustos clásicos y bayesianos con aplicaciones al mercado peruano de acciones,"Vera Chipoco, Alberto Manuel",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","El Modelo del Portafolio, propuesto por Markowitz (1952), es uno de los más importantes
en el ámbito  nanciero. En él, un agente busca lograr un nivel óptimo de sus inversiones
considerando el nivel de riesgo y rentabilidad de un portafolio, conformado por un conjunto de acciones bursátiles.
En este trabajo se propone una extensión a la estimación clásica del riesgo en el Modelo del Portafolio usando Estimadores Robustos tales como los obtenidos por los métodos del Elipsoide de Volumen mínimo, el Determinante de Covarianza Mínima, el Estimador Ortogonalizado de Gnanadesikan y Kettenring, el Estimador con base en la matriz de Covarianzas de la distribución t-student Multivariada y la Inferencia Bayesiana. En este último caso se hace uso de los modelos Normal Multivariado y t-student multivariado. En todos los modelos descritos se evalúa el impacto económico y las bondades estadísticas que se logran si se usaran estas técnicas en el Portafolio del inversionista en lugar de la estimación clásica. Para esto se utilizarán activos de la Bolsa de Valores de Lima.",2015-07-20
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Una aplicación de intervalos de confianza para la mediana de supervivencia en el modelo de regresión de Cox,"Mondragón Arbocco, Jorge Adolfo",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","El presente trabajo estudiará el método propuesto por Tze y Zheng (2006) aplicándolo a la obtención de intervalos de confianza para la mediana de supervivencia de líneas móviles de una empresa de telecomunicaciones. Esta metodología se aplicará con el objeto de conocer el riesgo de vida promedio de la línea móvil así como de qué manera inciden las covariables sobre el tiempo hasta el incumplimiento del pago de los clientes de la empresa.
Para ello se hará uso de una extensión del modelo de Cox haciendo uso de la estimación máximo verosímil para obtener nuevas estimaciones del vector de parámetros mediante el método bootstrap lo que permita la construcción de los intervalos de confianza para la mediana de supervivencia.",2015-07-17
Pontificia Universidad Católica del Perú. Escuela de Posgrado,An empirical application of stochastic volatility models to Latin-American stock returns using GH skew student's t-distribution,"Lengua Lafosse, Patricia",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","This paper represents empirical studies of stochastic volatility (SV) models for daily stocks returns data of a set of Latin American countries (Argentina, Brazil, Chile, Mexico and Peru) for the sample period 1996:01-2013:12. We estimate SV models incorporating both leverage effects and skewed heavy-tailed disturbances taking into account the GH Skew Student’s t-distribution using the Bayesian estimation method proposed by Nakajima and Omori (2012). 
A model comparison between the competing SV models with symmetric Student´s t-disturbances is provided using the log marginal likelihoods in the empirical study. A prior sensitivity analysis is also provided. The results suggest that there are leverage effects in all indices considered but there is not enough evidence for Peru, and skewed heavy-tailed disturbances is confirmed only for Argentina, symmetric heavy-tailed disturbances for Mexico, Brazil and Chile, and symmetric Normal disturbances for Peru. Furthermore, we find that the GH Skew Student s t-disturbance distribution in the SV model is successful in describing the distribution of the daily stock return data for Peru, Argentina and Brazil over the traditional symmetric Student´s t-disturbance distribution.",2015-07-17
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Un enfoque de credibilidad bajo espacios de Hilbert y su estimación mediante modelos lineales mixtos,"Ruíz Arias, Raúl Alberto",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","La teoría de la credibilidad provee un conjunto de métodos que permiten a una compañía de seguros ajustar las primas futuras, sobre la base de la experiencia pasada individual e información de toda la  cartera. En este trabajo presentaremos los principales modelos de credibilidad utilizados en la práctica, como lo son los  modelos de Bühlmann (1967), Bühlmann-Straub (1970), Jewell (1975) y Hachemeister (1975), todos ellos analizados en  sus propiedades desde un punto de vista geométrico a través de la teoría de espacios de Hilbert y en su estimación mediante el uso de los modelos lineales mixtos. Mediante un estudio de simulación se mostrará la ventaja de utilizar este último enfoque de estimación.",2013-04-08
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Inferencia bayesiana en el modelo de regresión spline penalizado con una aplicación a los tiempos en cola de una agencia bancaria,"Huaraz Zuloaga, Diego Eduardo",Magíster en Estadística,"Bayes Rodríguez, Cristian Luis","En diversos campos de aplicación se requiere utilizar modelos de regresión para analizar la relación entre dos variables. Cuando esta relación es compleja, es difícil modelar los datos usando técnicas paramétricas tradicionales, por lo que estos casos requieren de la flexibilidad de los modelos no paramétricos para ajustar los datos. Entre los diferentes modelos no paramétricos está la regresión spline penalizada, que puede ser formulada dentro de un marco de modelos lineales mixtos. De este modo, los programas computacionales desarrollados originalmente para la inferencia clásica y Bayesiana de modelos mixtos pueden ser utilizados para estimarlo.
La presente tesis se centra en el estudio de la inferencia Bayesiana en el modelo de regresión spline penalizado. Para lograr esto, este trabajo proporciona un marco teórico breve de este modelo semiparamétrico y su relación con el modelo lineal mixto, la inferencia Bayesiana de este modelo, y un estudio de simulación donde se comparan la inferencia clásica y Bayesiana en diferentes escenarios considerando diversos valores del n umero de nodos, tamaños de muestra y niveles de dispersión en la data simulada. Finalmente, en base a los resultados del estudio de simulación, el modelo se aplica para estimar el tiempo de espera en cola de los clientes en agencias bancarias con el fin de calcular la capacidad de personal óptima bajo determinadas metas de nivel de servicio.",2013-04-08
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Análisis de votos electorales usando modelos de regresión para datos de conteo,"Contreras Vilca, Norma",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","Se presentan dos modelos de regresión para datos de conteo: el modelo de regresión
Poisson y modelo de regresión Binomial Negativa dentro del marco de los Modelos Lineales Generalizados. Los modelos son aplicados inicialmente a un conjunto de datos conocido como ((The Aircraft Damage)) presentado en Montgomery (2006) referido al número de daños en las aeronaves
durante la guerra de Vietnam.
La principal aplicación de este trabajo sería el análisis de los votos obtenidos por el candidato
Ollanta Humala Tasso en los resultados de las ((Elecciones Generales y Parlamento Andino
2011)), analizamos los datos de la primera vuelta a nivel de regiones considerando diversos
predictores. Ambos conjunto de datos, presentan sobredispersión, esto es una varianza mayor que la media, bajo estas condiciones el modelo de Regresión Binomial Negativa resulta m as adecuado que
el modelo de Regresión Poisson.
Adicionalmente, se realizaron estudios de diagnósticos que confirman la elección del modelo
Binomial Negativa como el más apropiado para estos datos.",2013-04-08
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos de regresión binaria Skew probit para el calculo de probabilidad de default en el ámbito del sistema financiero,"Pantoja Marin, Luis",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","La presente investigación se fundamenta en el uso o aplicación de Modelos Skew Probit con enlace asimétrico desde un enfoque Bayesiano. Los modelos a usar incorporan la posibilidad de usar enlaces asimétricos para estimar la probabilidad de y i =1 en muestras no balanceadas (alta proporción de ceros y por ende pequeña proporción de unos). La formulación general de esto modelos es debida a Bazán, Bolfarine y Branco (2010).
Aunque en estos modelos inicialmente su computación es complicada se usaron Cadenas de Markov por Monte Carlo (MCMC) o muestreo Gibbs (para la aplicación de estos procedimientos ver Carlin y Polson, 1992) que hacen simple la formulación del modelo y por tanto simple su implementación usando el software WinBugs (los códigos de los diferentes modelos utilizados fueron obtenidos en el programa BRMUW propuesto por Bazán y Bayes, 2010).
De acuerdo al análisis y estudio de aplicación realizado sobre una muestra de clientes de préstamos pertenecientes a una entidad micro financiera, aquellos modelos Skew Probit BBB y Estándar presentan los mejores indicadores de eficiencia.
El análisis sobre datos reales señala que el modelo tradicional Probit presenta un 56.6% (371/664) de mala clasificación versus los modelos Estándar y BBB que en promedio muestran dicho indicador alrededor de 43% (290/664).
El análisis mediante curvas COR (Receiver Operating Characteristic) ratifica lo mencionado; el área debajo de las curvas superan el 0.74 de 1 para el modelo BBB, mientras que dicho dato es de 0.70 para el caso del modelo simétrico tradicional probit. Por tanto la sensibilidad y especificidad (eficiencia) es mayor para aquellos modelos Skew Probit (mejor modelo BBB).
Dentro de los modelos con Enlaces Asimétricos los modelos (SP) BBB y Estándar son los que presentan mejores indicadores de ajuste e información as__ como mejoran la sensibilidad y especificidad de un determinado modelo. Finalmente, se pretende la sistematización de la propuesta a nivel de la entidad micro financiera y su aplicación en la estimación de la probabilidad de default de créditos pero aplicado en todos los tipos de créditos.",2013-02-05
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelo de Rasch dicotómico con aplicación a la educación,"Chincaro Del Coral, Omar Antonio",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","En investigaciones de origen cuantitativo generalmente se emplean instrumentos de medición que generan base de datos dicotómicas, en la cual cada persona responde las preguntas o ítems del instrumento. Subyacente a estas respuestas existen variables no observables o variables latentes que caracterizan a las personas evaluadas y a los ítems del instrumento de medición utilizado. En este trabajo se modeló la probabilidad de responder correctamente al ítem en función a sus parámetros mediante el uso de los modelos logísticos o modelos de Rasch. Considerando las respuestas a estas variables latentes de las personas, de lo ítems, y sus supuestos se estimó los parámetros a partir de la función de verosimilitud del modelo.

En esta tesis se mostró diferentes métodos de estimación como el de Máxima Verosimilitud Marginal (MVM) que depende de las puntuaciones que se obtenga en cada ítem, el de Máxima Verosimilitud Condicional (MVCOND) que considerara patrones de respuesta, el método de Máxima Verosimilitud Conjunta (MVC) y el método Bayesiano utilizando Cadenas de Markov y métodos de Monte Carlo (MCMC) como el algoritmo Gibbs Sampling. El Método Bayesiano fué analizado bajo dos esquemas: adaptative rejection sampling (ARS) y el data argumentation gibbs sampling (DAGS). Con estos métodos se estimaron los parámetros de los ítems y las personas evaluadas, los cuales se compararon con estudios de simulación determinándose que el mejor método de estimación es el Bayesiano. El método bayesiano presenta las estimativas más precisas considerando diferentes escenarios de tamaño de muestra y número de ítems frente a los otros métodos de estimación. Adicionalmente no tiene restricción en la estimación frente a valores extremos y finalmente es un método conjunto que estima al mismo tiempo habilidades y dificultades a diferencia de otros métodos que sólo estiman dificultades u otros que estiman ambos pero baja precisión. Finalmente se realizó una aplicación del modelo en el ámbito educacional.",2012-08-17
Pontificia Universidad Católica del Perú. Escuela de Posgrado,"Estimación no paramétrica en un proceso de Markov ""enfermedad-muerte"" aplicado a una base de clientes de una AFP","Requena Espinoza, Genaro",Magíster en Estadística,"Doig Camino, Elizabeth","En el presente trabajo, se estudian las propiedades del método de estimación no paramétrico en un modelo de “Enfermedad - Muerte"" de proceso de Markov. Este modelo posee tres estados 1, 2 y 3 correspondientes a “salud"", “enfermedad"" y “muerte"" respectivamente y solo admite las transiciones de 1-2, 1-3 y 2-3, asimismo a este proceso se le denomina de Markov porque la probabilidad de transición de un estado a otro es independiente del tiempo de permanencia en el estado inicial.
Las funciones de tiempo de muerte y enfermedad, así como la función de riesgo de muerte dada la enfermedad son los parámetros del modelo \Enfermedad - Muerte"". Sin embargo la estimación de estas funciones del modelo no es directa pues existen dos formas de censura en los datos: los intervalos censurados y la pérdida de estados de transición; por lo que se utiliza un algoritmo de autoconsistencia para calcular estos estimadores.
Los intervalos censurados y la pérdida de estados de transición se generan porque los pacientes son evaluados periódicamente. En un intervalo censurado (t1 , t2) se conoce que la enfermedad ocurrió entre un tiempo t1 y t2 pero no el momento exacto, mientras que para la pérdida de estados de transición se sabe que la enfermedad no ha ocurrido hasta la última medición pero se desconoce si la enfermedad ocurre entre esta última medición y el tiempo final del estudio.
En la aplicación del modelo \Enfermedad - Muerte"" de proceso de Markov a una base de clientes de una administradora de fondos de pensiones (AFP) se consideran los intervalos censurados para los reclamos de los clientes, as__ como la pérdida de estados de transición para los traspasos. Modelar los tiempos de traspaso y de reclamo de los afiliados bajo un proceso de Markov \Enfermedad - Muerte"" con intervalos censurados y pérdida de estados de transición intermedia, aumenta la precisión de los estimadores de las funciones de tiempo y riesgo.",2012-08-16
Pontificia Universidad Católica del Perú. Escuela de Posgrado,Modelos testlet logísticos y logísticos de exponente positivo para pruebas de compresión de textos,"Flores Ari, Sandra Elizabeth",Magíster en Estadística,"Bazán Guzmán, Jorge Luis","Los modelos de Teoría de Respuesta al Item (TRI) para datos binarios multivariados,
permiten estimar una medida latente (de habilidad) a partir de información observada, que puede ser respuestas dicotómicas (de éxito y fracaso) a un conjunto de ítems de una determinada prueba. Uno de los supuestos críticos en los modelos TRI es la independencia condicional de los ítems, que permite el cálculo directo de la verosimilitud del modelo. En muchas situaciones de evaluación este supuesto no se cumple, como es el caso de pruebas de comprensión de textos, en la que se presenta un texto y luego varias preguntas relacionadas con ese texto. Este tipo de estructuras son denominadas como testlets. Bradlow et al. (1999) desarrollaron una parametrización adicional para recoger el efecto de esta dependencia. A partir de este trabajo se presenta el modelo Testlet logístico y se propone el modelo Testlet logístico de exponente positivo (2LPET), que es una extensión del modelo LPE propuesto por Samejima (1999) y Bazan y Bolfarine (2010) y considera enlaces asimétricos.
Se desarrollaron varios estudios de simulación en los que se muestra que cuando se tiene testlets, los modelos Testlet recuperan mejor los parámetros respecto a los modelos TRI.
Finalmente se realizó una aplicación con datos del Ministerio de Educación, específicamente con los resultados de la prueba de comprensión de textos de la Evaluación Censal de Estudiantes (ECE) dirigido a estudiantes de segundo grado de primaria, en un conjunto de escuelas de Lima metropolitana. De los resultados obtenidos se concluye que los modelos TRI sobreestiman la medida de habilidad respecto a los modelos Testlets y además la información de la prueba es mejor distribuida por el modelo propuesto.",2012-08-16
Pontificia Universidad Católica del Perú. Escuela de Posgrado,El análisis de correspondencias conjunto y múltiple ajustado,"Saavedra López, Ricardo Elías",Magíster en Estadística,"Valdivieso Serrano, Luis Hilmar","Esta tesis presenta una revisión de los fundamentos teóricos de dos de las más recientes
extensiones de la técnica estadística conocida como análisis de correspondencia (AC): el análisis de correspondencia conjunto (ACC) y el análisis de correspondencia múltiple ajustado (ACMA); y muestra una aplicación práctica de éstas a una encuesta de egresados de la Pontificia Universidad Católica del Perú.
El análisis de correspondencia simple (ACS) es el primer alcance del análisis de correspondencias y se presenta cuando cada categoría de una variable se describe en función de la dependencia existente de los valores de otra única variable. Su extensión a más de 2 variables es conocida como el análisis de correspondencia múltiple (ACM).
Si bien se puede encontrar literatura sobre el ACS y el ACM, es importante destacar que
el ACC y el ACMA han sido poco difundidos, encontrándose escasa literatura sobre el tema, más aún, en nuestro idioma. Por lo tanto, se hace necesaria una revisión de las dos primeras a modo de contexto y una presentación metodológica y detallada de las dos últimas.
Con la aplicación práctica se pretende obtener una representación de las facultades de los egresados de la PUCP en función del ingreso en su primer empleo relacionado con la formación recibida en la universidad y la percepción del grado de desarrollo de la competencia de comunicación recibida en la universidad. Esta aplicación consistiría en aplicar los 4 métodos descritos, comparándolos mediante nuevas técnicas que permiten reproducir las tablas de contingencia originales a partir de las representaciones obtenidas por los métodos indicados.",2012-08-15
